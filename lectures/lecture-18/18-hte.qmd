---
title: QTM 385 - Experimental Methods
subtitle: Lecture 18 - Heterogeneous Effects
author:
  - name: Danilo Freire
    email: danilo.freire@emory.edu
    affiliations: Emory University
format:
  clean-revealjs:
    self-contained: true
    code-overflow: wrap
    footer: "[Heterogeneous Effects](https://raw.githack.com/danilofreire/qtm385/main/lectures/lecture-18/18-hte.html)"
transition: slide
transition-speed: default
scrollable: true
engine: knitr
revealjs-plugins:
  - multimodal
editor:
  render-on-save: true
---

# Hello, everyone! üëã <br> How are you today? {background-color="#2d4563"}

# Brief recap üìö {background-color="#2d4563"}

## Brief recap üìö

:::{style="margin-top: 20px; font-size: 24px;"}
:::{.columns}
:::{.column width="50%"}
**Centola (2010): Online Behaviour Spread**

- [Experimentally varied network structure]{.alert} (clustered vs. random) in an online health community
- Measured spread of adopting a health forum registration
- [Finding]{.alert}: Behaviour spread significantly farther and faster in [clustered (high reinforcement) networks]{.alert} compared to random networks
- [Implication]{.alert}: Network structure critically affects diffusion, especially for behaviours requiring social proof. Weak ties might be less effective for complex contagions
:::

::: {.column width="50%"}
**Paluk et al. (2021): Conflict Climate Change**

- Field experiment in [56 US middle schools]{.alert} using social networks to reduce conflict
- Randomly assigned schools to intervention or control
- Intervention: [Student-nominated "social referents"]{.alert} to model anti-conflict norms.
- [Finding]{.alert}: Targeting influential [social referents]{.alert} was effective in reducing overall student conflict (by ~30%) than targeting random students
- [Mechanism]{.alert}: Changed perceived social norms around conflict within the school network ([spillover effect]{.alert})
:::
:::
:::

# Today's plan üìÖ {background-color="#2d4563"}

## Heterogeneous Treatment Effects (HTE)
### Moving Beyond the Average

:::{style="margin-top: 30px; font-size: 24px;"}
:::{.columns}
:::{.column width=50%}
- Why average treatment effects ([ATEs]{.alert}) aren't the whole story
- Defining and understanding [treatment effect variability]{.alert}
- Fundamental challenge: We [cannot directly observe individual treatment effects]{.alert} or their variance
- Methods for exploring HTE:
  - [Bounding the variance]{.alert} of treatment effects
  - [Testing for the presence]{.alert} of heterogeneity
:::

:::{.column width=50%}
- Structured approaches:
  - [Treatment-by-Covariate Interactions]{.alert} (Subgroup Analysis / CATEs)
  - [Treatment-by-Treatment Interactions]{.alert} (Factorial Designs)
- [Modelling HTE]{.alert} using regression
- Pitfalls and best practices:
  - [Multiple comparisons]{.alert}
  - [Causal interpretation]{.alert} challenges
:::
:::
:::

# Why Look Beyond the ATE? {background-color="#2d4563"}

## The Limits of Averages

:::{style="margin-top: 30px; font-size: 27px;"}
- To this point, we've focused mainly on estimating the [Average Treatment Effect (ATE)]{.alert}
- Assumption: The treatment effect might be similar across individuals
- [Reality]{.alert}: Interventions rarely affect everyone identically. Effects often vary across individuals, groups, or contexts
- [Practical Value]{.alert}: Policymakers want to know *who* benefits most (or least) from an intervention and *under what conditions*
  - Targeting resources effectively
  - Tailoring programs
- [Scientific Value]{.alert}: Understanding *why* effects vary helps uncover causal mechanisms
  - What makes an intervention work (or not)?
:::

## Examples of Heterogeneity

:::{style="margin-top: 30px; font-size: 30px;"}
- [School Choice]{.alert}: Policies allowing school choice might benefit children whose parents prioritise academic quality more than those whose parents prioritise proximity
- [Job Training]{.alert}: Programs might increase earnings for voluntary participants but have no effect on those required to attend for public assistance eligibility
- [Tax Compliance]{.alert}: Efforts to increase compliance might work differently depending on whether taxpayers can easily conceal income
- [Advertising]{.alert}: A campaign targeting teenagers might alienate older consumers
:::

# The Fundamental Problem of HTE Inference {background-color="#2d4563"}

## Defining Treatment Effect Heterogeneity

:::{style="margin-top: 30px; font-size: 28px;"}
- Individual treatment effect: $\tau_i = Y_i(1) - Y_i(0)$
- Treatment effect heterogeneity refers to the [variance of individual treatment effects]{.alert} across subjects: $Var(\tau)$
- We want to estimate $Var(\tau)$ and test if $Var(\tau) > 0$
- Recall the relationship:

$$Var(\tau) = Var(Y_i(1) - Y_i(0))$$
$$Var(\tau) = Var(Y_i(1)) + Var(Y_i(0)) - 2Cov(Y_i(1), Y_i(0))$$

- This equation highlights the challenge...
:::

## What Experimental Data Tell Us (and What They Don't)

:::{style="margin-top: 30px; font-size: 26px;"}
- Experiments give us samples of $Y_i(1)$ (from the treatment group) and $Y_i(0)$ (from the control group)
- From these, we can estimate the [marginal distributions]{.alert} of $Y(1)$ and $Y(0)$
- We can estimate $E[Y(1)]$, $E[Y(0)]$, $Var(Y(1))$, and $Var(Y(0))$
- **BUT:** We *never* observe both $Y_i(1)$ and $Y_i(0)$ for the same individual $i$
- Therefore, we [cannot directly estimate the joint distribution]{.alert} of potential outcomes
- So we [cannot estimate $Cov(Y_i(1), Y_i(0))$]{.alert}
- Without the covariance, we [cannot directly calculate $Var(\tau)$]{.alert}!
:::

## Simple Example Illustrating the Problem

:::{style="margin-top: 30px; font-size: 22px;"}
- Suppose $N=6$ subjects. We observe outcomes:
  - Control Group ($Y(0)$): {1, 2, 3} -> $\hat{Var}(Y(0))=1$
  - Treatment Group ($Y(1)$): {4, 5, 6} -> $\hat{Var}(Y(1))=1$
- Estimated ATE = $E[Y(1)] - E[Y(0)] = 5 - 2 = 3$
- What is $Var(\tau)$? It depends on how potential outcomes are paired (which we don't know):
  - **Scenario 1 (Perfect Positive Correlation):** Pairs are {(1,4), (2,5), (3,6)}
    - Individual effects $\tau_i$ are {3, 3, 3}
    - $Var(\tau) = 0$. [Homogeneous effect]{.alert}
  - **Scenario 2 (Perfect Negative Correlation):** Pairs are {(1,6), (2,5), (3,4)}
    - Individual effects $\tau_i$ are {5, 3, 1}
    - $Var(\tau) = Var(\{5,3,1\}) = 4$. [Heterogeneous effect]{.alert}
  - **Scenario 3 (Mixed):** Pairs are {(1,6), (2,4), (3,5)}
    - Individual effects $\tau_i$ are {5, 2, 2}
    - $Var(\tau) = Var(\{5,2,2\}) = 3$. [Heterogeneous effect]{.alert}

- Experimental data alone do not distinguish these scenarios!
:::

# Detecting Heterogeneity: Bounds & Tests {background-color="#2d4563"}

## Bounding the Variance of Treatment Effects

:::{style="margin-top: 30px; font-size: 24px;"}
- Since we can't estimate $Cov(Y(1), Y(0))$, we can't pinpoint $Var(\tau)$.
- However, we can [estimate bounds on $Var(\tau)$]{.alert} by considering the most extreme possible correlations (Heckman, Smith, Clements 1997)
- **Procedure (for equal group sizes):**
  1. Sort observed $Y(0)$ values ascendingly
  2. Sort observed $Y(1)$ values ascendingly
  3. **Lower Bound for $Var(\tau)$:** Pair the sorted values rank-by-rank (1st with 1st, 2nd with 2nd, ...). Calculate the variance of the resulting $\tau_i$ estimates. This assumes [maximum possible positive covariance]{.alert}
  4. **Upper Bound for $Var(\tau)$:** Pair the sorted $Y(0)$ values (ascending) with sorted $Y(1)$ values in *descending* order (1st $Y(0)$ with last $Y(1)$, ...). Calculate the variance of the resulting $\tau_i$. This assumes [maximum possible negative covariance]{.alert}
- If the number of subjects differs, pair percentiles instead of ranks
- A lower bound substantially > 0 suggests heterogeneity
:::

## Testing for Heterogeneity: Comparing Variances

:::{style="margin-top: 30px; font-size: 26px;"}
- A simpler approach: Test the null hypothesis $H_0: Var(\tau) = 0$ (homogeneous effects)
- If $\tau_i = \tau$ (constant) for all $i$, then $Var(\tau)=0$
- Also, if $\tau$ is constant, $Cov(Y(0), \tau) = Cov(Y(0), \text{constant}) = 0$
- Recall: $Var(Y(1)) = Var(Y(0)) + Var(\tau) + 2Cov(Y(0), \tau)$
- Under $H_0: Var(\tau)=0$, this simplifies to $Var(Y(1)) = Var(Y(0))$
- **Test Idea:** If we observe significantly different variances in the treatment and control groups, we can [reject the null hypothesis of homogeneous effects]{.alert}
- [Caution]{.alert}: Equality of variances does *not* strictly prove homogeneity (could have $Var(\tau) = -2Cov(Y(0), \tau)$), but large differences suggest heterogeneity
:::

## Example: Teacher Incentives Variance Test

:::{style="margin-top: 30px; font-size: 22px;"}
- Revisit the teacher incentives experiment (Muralidharan & Sundararaman 2011)
- Outcome: Change in school test scores (post-pre)
- Observed variances:
  - Control group: $\hat{Var}(Y(0)) = 59.29$
  - Treatment group: $\hat{Var}(Y(1)) = 91.20$
- Observed difference: $|91.20 - 59.29| = 31.91$. Is this difference large enough to reject $H_0$?
- **Randomisation Inference:**
  1. Assume constant treatment effect (ATE = 3.50) for all schools (generate full potential outcomes schedule)
  2. Repeat random assignment to treatment/control 100,000 times
  3. For each simulation, calculate the absolute difference in variances between the simulated T/C groups
  4. Find the proportion of simulated differences >= 31.91
- Result: p-value = 0.088
- **Conclusion:** Cannot reject $H_0$ at $\alpha=0.05$, but the borderline p-value [hints at possible heterogeneity]{.alert}. Incentives *might* affect schools differently
:::

## Limitations of Basic Methods

:::{style="margin-top: 30px; font-size: 28px;"}
- Bounds on $Var(\tau)$ are often [very wide]{.alert}, making them uninformative
- Tests comparing $Var(Y(1))$ and $Var(Y(0))$ often [lack statistical power]{.alert}, especially with smaller samples
- These methods don't tell us *why* effects might vary or *who* is affected differently
- They serve as a [preliminary step]{.alert}. Significant results encourage more structured investigation

‚û°Ô∏è Need approaches that examine variation across specific subgroups or conditions
:::

# Treatment-by-Covariate Interactions (CATEs) üìä {background-color="#2d4563"}

## Conditional Average Treatment Effects (CATEs)

:::{style="margin-top: 30px; font-size: 26px;"}
- Idea: Partition subjects into subgroups based on [pre-treatment covariates (X)]{.alert} and estimate the ATE within each subgroup
- **CATE:** Conditional Average Treatment Effect
  - $CATE(X=x) = E[Y_i(1) - Y_i(0) | X_i = x]$
- Example: Estimate the ATE for men vs. women, old vs. young, high income vs. low income
- **Interaction Effect:** The difference between CATEs across subgroups
  - $Interaction = CATE(X=x_1) - CATE(X=x_2)$
- This approach uses observable characteristics to explore *potential* sources of heterogeneity
- Often guided by theory about *why* effects might differ
:::

## Example: Teacher Incentives & Parent Literacy

:::{style="margin-top: 30px; font-size: 26px;"}
- Researchers explored if teacher incentive effects varied by school characteristics (Muralidharan & Sundararaman 2011)
- Covariate: Average parent literacy level (pre-treatment). Partitioned schools into below-median and above-median literacy
- **Estimated CATEs:**
  - Low Literacy Schools: CATE = 11.14 - 7.83 = [3.31]{.alert}
  - High Literacy Schools: CATE = 12.26 - 8.57 = [3.69]{.alert}
- **Interaction Effect:** 3.69 - 3.31 = 0.38.
- **Hypothesis Test:** Is this difference statistically significant?
  - Using randomisation inference (or regression F-test), p = 0.88
  - **Conclusion:** [No significant evidence]{.alert} that the treatment effect differs based on parental literacy levels in the school
:::

## Regression Framework for CATEs

:::{style="margin-top: 30px; font-size: 26px;"}
- Regression provides a flexible way to estimate and test CATEs and interactions
- Let $I_i$ be the treatment indicator (1=Treat, 0=Control)
- Let $P_i$ be the covariate indicator (e.g., 1=High Literacy, 0=Low Literacy)
- **Null Model (Homogeneous Effect):**
  $Y_i = \alpha + \beta I_i + \gamma P_i + u_i$
  - Assumes a single ATE ($\beta$)
- **Alternative Model (Interaction):**
  $Y_i = \alpha + \beta I_i + \gamma P_i + \delta (I_i \times P_i) + u_i$
  - CATE for Low Literacy ($P_i=0$): $\beta$
  - CATE for High Literacy ($P_i=1$): $\beta + \delta$
  - [Interaction Effect: $\delta$]{.alert}
- **Testing:** Use an F-test to see if the model with the interaction term ($\delta$) fits significantly better than the null model (i.e., test $H_0: \delta = 0$)
- In the teacher incentive example, the F-test yields p = 0.88, matching the randomisation inference
:::

# Cautions with CATEs ‚ö†Ô∏è {background-color="#2d4563"}

## The Multiple Comparisons Problem

:::{style="margin-top: 30px; font-size: 23px;"}
- Datasets often contain many potential covariates (age, gender, income, education, location, etc.)
- If we test for interactions with many covariates, the chance of finding a "significant" interaction [purely by chance increases]{.alert}
- Example: Test 20 uncorrelated covariates for interaction at $\alpha=0.05$. Assume the true effect is homogeneous
  - Probability of finding *at least one* significant interaction: $1 - (1 - 0.05)^{20} \approx 0.64$. (High risk of false discovery!)
- **Solution 1: Bonferroni Correction:**
  - If conducting $q$ tests, adjust significance level to $\alpha / q$
  - E.g., for 20 tests at $\alpha=0.05$, require $p < 0.05 / 20 = 0.0025$
  - Simple, but can be overly conservative (reduces power)
- **Solution 2: Pre-specification:**
  - Specify the few theoretically motivated interactions you will test *before* looking at the data (e.g., in a Pre-Analysis Plan)
:::

## Correlation vs. Causation in Subgroups

:::{style="margin-top: 30px; font-size: 26px;"}
- A fundamental limitation: Covariates used for subgroup analysis are [observed characteristics, not randomly assigned treatments]{.alert}
- Finding that CATEs differ between, say, high-education and low-education groups means the treatment effect *correlates* with education
- It does **not** necessarily mean that *changing* someone's education level would change how they respond to the treatment
- Education might be a marker for other underlying factors (e.g., income, access to information, underlying health) that are the "true" drivers of the heterogeneity
- **Subgroup analysis is essentially observational/descriptive regarding the source of heterogeneity**
- It's useful for prediction (who is likely to respond more?) and generating hypotheses, but not for establishing the *causal impact* of the covariate itself on the treatment effect
:::

## Example: Interpreting Voter Turnout Interaction

:::{style="margin-top: 30px; font-size: 25px;"}
- Gerber, Green, Larimer (2008) sent mailers showing recipients' own (and neighbours') past voting records to encourage turnout
- Finding: Mailer effect (ATE) was larger among people who *had* voted in a previous election (2004) compared to those who hadn't
- [Superficial interpretation]{.alert}: Seeing your *past voting* record is more motivating than seeing your *past non-voting* record
- **Problem:** Past voting behaviour (the covariate) is not random. People who voted in 2004 are different from those who didn't in many ways (more politically engaged, different demographics, etc.). The mailer content *also* differs (shows voting vs. non-voting)
- [Follow-up Experiment (Gerber, Green, Larimer 2010)]{.alert}: *Randomly varied* whether the mailer showed a record of voting or a record of abstention
- [Result]{.alert}: Showing a record of *abstention* was significantly *more* motivating
- **Lesson:** Subgroup analysis conflated the *type of person* with the *content of the message*. Direct experimental manipulation was needed to isolate the causal effect of the message content
:::

# Treatment-by-Treatment Interactions (Factorial Designs) üß™ {background-color="#2d4563"}

## Beyond Covariates: Manipulating Multiple Factors

:::{style="margin-top: 30px; font-size: 26px;"}
- To make *causal* claims about *why* treatment effects vary, we need to experimentally manipulate the hypothesised moderating factors
- **Factorial Design:** An experimental design that includes two or more "factors" (independent variables), where subjects are randomly assigned to a combination of the levels of these factors
- Example: Factor A (Treatment vs. Control), Factor B (Context 1 vs. Context 2).
- Subjects randomly assigned to one of four groups: (Treat, Cxt 1), (Treat, Cxt 2), (Control, Cxt 1), (Control, Cxt 2).
- Allows us to estimate:
  - Main effect of Factor A
  - Main effect of Factor B
  - **Interaction effect:** Does the effect of Factor A *depend* on the level of Factor B?
- This provides stronger causal evidence about moderators than treatment-by-covariate analysis
:::

## Examples of Factorial Designs

:::{style="margin-top: 30px; font-size: 29px;"}
- **Gerber & Green (2000) Voter Mobilisation:** Crossed multiple communication methods (Factor 1: Canvassing Y/N, Factor 2: Phone Call Y/N, Factor 3: Direct Mail Y/N) to see if effects were additive or interactive
- **Olken (2007) Corruption Monitoring:** Crossed top-down audits (Factor 1: Audit Y/N) with bottom-up community monitoring (Factor 2: Invitations to meetings Y/N) in Indonesian road projects. Tested if audits were more effective when community was involved
- **Rosen (2010) Discrimination:** Crossed putative email sender ethnicity (Factor 1: Hispanic/Non-Hispanic name) with email grammar quality (Factor 2: Good/Bad grammar) sent to state legislators. Tested if ethnic discrimination depended on perceived social class (signalled by grammar)
:::

## Rosen (2010) Example: Ethnicity and Grammar

:::{style="margin-top: 20px; font-size: 23px;"}
**Research Question:** Do US state legislators respond differently to constituent emails based on perceived ethnicity and writing quality?

**2x2 Factorial Design:**
- Factor 1: Sender Name (Colin Smith vs. Jos√© Ramirez)
- Factor 2: Email Grammar (Good vs. Bad)

**Outcome:** Percentage of emails receiving a reply

**Results (Subset, N=100 per cell):**

|                     | Colin Smith (Non-Hispanic) | Jos√© Ramirez (Hispanic) | Difference (Jos√© - Colin) |
| :------------------ | :------------------------: | :---------------------: | :-----------------------: |
| **Good Grammar**    |             52%            |           37%           |          [-15%]{.alert}   |
| **Bad Grammar**     |             29%            |           34%           |          [+5%]{.alert}    |
| **Difference (Bad-Good)** |          [-23%]{.alert}   |          [-3%]{.alert}    |                           |

- **Interpretation:**
  - With good grammar, Colin gets more replies (-15% effect for Jos√©)
  - With bad grammar, Jos√© gets slightly *more* replies (+5% effect)
  - The effect of ethnicity *depends on* grammar quality ([Interaction]{.alert})
  - Poor grammar hurts Colin much more (-23%) than Jos√© (-3%)
:::

## Advantages and Caveats of Factorial Designs

:::{style="margin-top: 30px; font-size: 27px;"}
- **Advantages:**
  - Allows causal estimation of [interaction effects]{.alert}
  - Efficient way to study multiple factors simultaneously
  - Can reveal complex relationships (e.g., conditions where a treatment is effective/ineffective)
- **Caveats:**
  - Require larger sample sizes to detect interactions (interactions are often smaller than main effects)
  - Can become complex logistically with many factors/levels
  - [Non-compliance]{.alert} can be problematic: estimating effects for those receiving *multiple* treatments requires sufficient compliers in those specific cells, which can be rare
:::

# Modelling HTE with Regression üìà {background-color="#2d4563"}

## Extending the Regression Framework

:::{style="margin-top: 30px; font-size: 27px;"}
- Regression is a powerful tool for modelling both treatment-by-covariate and treatment-by-treatment interactions.
- **Systematic Heterogeneity:** Variation in $\tau$ that can be predicted by observed covariates or experimental factors (modelled by interaction terms).
- **Idiosyncratic Heterogeneity:** Residual variation in $\tau$ not explained by the model (part of the error term $u_i$).
- We use interaction terms to capture systematic heterogeneity.
:::

## Modelling Treatment-by-Treatment Interaction

:::{style="margin-top: 30px; font-size: 22px;"}
- Let $J_i = 1$ if sender is Jos√©, 0 if Colin
- Let $G_i = 1$ if grammar is bad, 0 if good
- Model: $Y_i = \alpha + \beta J_i + \gamma G_i + \delta (J_i \times G_i) + u_i$
- **Interpreting Coefficients:**
  - $\alpha$: Mean outcome for baseline (Colin, Good Grammar) = 52%
  - $\beta$: Effect of Jos√© vs. Colin, *when grammar is good* = 37% - 52% = [-15%]{.alert}
  - $\gamma$: Effect of Bad vs. Good grammar, *when sender is Colin* = 29% - 52% = [-23%]{.alert}
  - $\delta$: Interaction effect. How the effect of Jos√© changes when grammar goes from good to bad.
    - Effect of Jos√© (Bad Grammar) = ($\alpha + \gamma$) + ($\beta + \delta$)
    - Effect of Jos√© (Good Grammar) = $\alpha + \beta$
    - Difference = $\gamma + \delta$
    - Alternatively: $\delta$ = (Effect of Bad Grammar for Jos√©) - (Effect of Bad Grammar for Colin) = (-3%) - (-23%) = [+20%]{.alert}
- **Estimates for Rosen data:** $\hat{Y}_i = 0.52 - 0.15 J_i - 0.23 G_i + 0.20 (J_i \times G_i)$
- **Testing the Interaction:** F-test for $H_0: \delta = 0$. In Rosen's data, p = 0.037. [Significant interaction]{.alert}
:::

## Automating the Search for Interactions

:::{style="margin-top: 30px; font-size: 27px;"}
- Manually specifying and testing interactions becomes infeasible with many covariates/factors.
- **Machine Learning Approaches:** Algorithms designed to automatically search for interactions.
  - E.g., [Generalised Random Forests (Athey & Imbens)](https://github.com/grf-labs/grf)
  - Methodically partition the data based on covariates to find subgroups with different treatment effects
  - Often use techniques like cross-validation to avoid overfitting and false discoveries
- Can be a powerful exploratory tool, especially in high-dimensional settings
- Still requires careful interpretation and follow-up validation
- Beyond the scope of this lecture, but good to be aware of
:::

# Summary {background-color="#2d4563"}

## Investigating Heterogeneous Treatment Effects

:::{style="margin-top: 20px; font-size: 22px;"}
:::{.columns}
:::{.column width="50%"}
- ATEs provide an incomplete picture; treatment effects often [vary systematically]{.alert}
- Fundamental challenge: $Cov(Y(1), Y(0))$ is [unidentified]{.alert}, so $Var(\tau)$ cannot be directly estimated from experimental data alone
- Preliminary checks:
  - [Bounding $Var(\tau)$]{.alert}: Often yields wide, uninformative bounds
  - [Comparing $Var(Y(1))$ and $Var(Y(0))$]{.alert}: Low power test for $H_0: Var(\tau)=0$.
- Structured approaches are needed for deeper insights
:::

::: {.column width="50%"}
- **Treatment-by-Covariate (Subgroup/CATEs):**
  - Estimates effects within subgroups defined by pre-treatment X
  - Useful for description and prediction
  - [Interpretation caution]{.alert}: Correlational regarding source of HTE; risk of multiple comparisons
- **Treatment-by-Treatment (Factorial Designs):**
  - Experimentally manipulate multiple factors
  - Allows [causal inference about interactions]{.alert}
  - More complex design, requires larger N
- **Regression Modelling:** Flexible tool for estimating and testing interactions
- **Best Practice:** [Pre-specify theoretically motivated interactions]{.alert} to test; treat exploratory findings cautiously pending replication
:::
:::
:::

# And that's all for today! üéâ {background-color="#2d4563"}

# See you next time! üòâ {background-color="#2d4563"}